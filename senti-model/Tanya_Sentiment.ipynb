{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     |████████████████████████████████| 636 kB 3.0 MB/s            \n",
      "\u001b[?25hCollecting nltk>=3.1\n",
      "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "     |████████████████████████████████| 1.5 MB 35.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     |████████████████████████████████| 306 kB 21.9 MB/s            \n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2021.10.23-cp37-cp37m-macosx_10_9_x86_64.whl (288 kB)\n",
      "     |████████████████████████████████| 288 kB 22.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Installing collected packages: regex, joblib, nltk, textblob\n",
      "Successfully installed joblib-1.1.0 nltk-3.6.5 regex-2021.10.23 textblob-0.17.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/qintianzhang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Congrats /r/anxiety we've all made it to Wedne...\n",
       "1    With both the subreddit and Discord continuing...\n",
       "2    I went to get my haircut and the person cuttin...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/reddit_data.csv').dropna()\n",
    "posts = df['body']\n",
    "posts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove punctuations\n",
    "2. Tokenization - Converting a sentence into list of words\n",
    "3. Remove stopwords\n",
    "4. Lammetization/stemming - Tranforming any form of a word to its root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>reddit_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>Let your light shine!</td>\n",
       "      <td>17</td>\n",
       "      <td>qc0aqd</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qc0a...</td>\n",
       "      <td>23</td>\n",
       "      <td>Congrats /r/anxiety we've all made it to Wedne...</td>\n",
       "      <td>1.634735e+09</td>\n",
       "      <td>Congrats ranxiety weve all made it to Wednesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>Looking for new mods! (subreddit and Discord)</td>\n",
       "      <td>12</td>\n",
       "      <td>qb0ort</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qb0o...</td>\n",
       "      <td>0</td>\n",
       "      <td>With both the subreddit and Discord continuing...</td>\n",
       "      <td>1.634606e+09</td>\n",
       "      <td>With both the subreddit and Discord continuing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>fuck</td>\n",
       "      <td>159</td>\n",
       "      <td>qe7rl0</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qe7r...</td>\n",
       "      <td>32</td>\n",
       "      <td>I went to get my haircut and the person cuttin...</td>\n",
       "      <td>1.635005e+09</td>\n",
       "      <td>I went to get my haircut and the person cuttin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                          title  score      id  \\\n",
       "0  anxiety                          Let your light shine!     17  qc0aqd   \n",
       "1  anxiety  Looking for new mods! (subreddit and Discord)     12  qb0ort   \n",
       "2  anxiety                                           fuck    159  qe7rl0   \n",
       "\n",
       "  subreddit                                                url  num_comments  \\\n",
       "0   Anxiety  https://www.reddit.com/r/Anxiety/comments/qc0a...            23   \n",
       "1   Anxiety  https://www.reddit.com/r/Anxiety/comments/qb0o...             0   \n",
       "2   Anxiety  https://www.reddit.com/r/Anxiety/comments/qe7r...            32   \n",
       "\n",
       "                                                body       created  \\\n",
       "0  Congrats /r/anxiety we've all made it to Wedne...  1.634735e+09   \n",
       "1  With both the subreddit and Discord continuing...  1.634606e+09   \n",
       "2  I went to get my haircut and the person cuttin...  1.635005e+09   \n",
       "\n",
       "                                        reddit_punct  \n",
       "0  Congrats ranxiety weve all made it to Wednesda...  \n",
       "1  With both the subreddit and Discord continuing...  \n",
       "2  I went to get my haircut and the person cuttin...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])     # this changes contraction to non-words (e.g. \"We've\" to \"weve\")\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "df['reddit_punct'] = df['body'].apply(lambda x: remove_punct(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>reddit_punct</th>\n",
       "      <th>reddit_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>Let your light shine!</td>\n",
       "      <td>17</td>\n",
       "      <td>qc0aqd</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qc0a...</td>\n",
       "      <td>23</td>\n",
       "      <td>Congrats /r/anxiety we've all made it to Wedne...</td>\n",
       "      <td>1.634735e+09</td>\n",
       "      <td>Congrats ranxiety weve all made it to Wednesda...</td>\n",
       "      <td>[congrats, ranxiety, weve, all, made, it, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>Looking for new mods! (subreddit and Discord)</td>\n",
       "      <td>12</td>\n",
       "      <td>qb0ort</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qb0o...</td>\n",
       "      <td>0</td>\n",
       "      <td>With both the subreddit and Discord continuing...</td>\n",
       "      <td>1.634606e+09</td>\n",
       "      <td>With both the subreddit and Discord continuing...</td>\n",
       "      <td>[with, both, the, subreddit, and, discord, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>fuck</td>\n",
       "      <td>159</td>\n",
       "      <td>qe7rl0</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qe7r...</td>\n",
       "      <td>32</td>\n",
       "      <td>I went to get my haircut and the person cuttin...</td>\n",
       "      <td>1.635005e+09</td>\n",
       "      <td>I went to get my haircut and the person cuttin...</td>\n",
       "      <td>[i, went, to, get, my, haircut, and, the, pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                          title  score      id  \\\n",
       "0  anxiety                          Let your light shine!     17  qc0aqd   \n",
       "1  anxiety  Looking for new mods! (subreddit and Discord)     12  qb0ort   \n",
       "2  anxiety                                           fuck    159  qe7rl0   \n",
       "\n",
       "  subreddit                                                url  num_comments  \\\n",
       "0   Anxiety  https://www.reddit.com/r/Anxiety/comments/qc0a...            23   \n",
       "1   Anxiety  https://www.reddit.com/r/Anxiety/comments/qb0o...             0   \n",
       "2   Anxiety  https://www.reddit.com/r/Anxiety/comments/qe7r...            32   \n",
       "\n",
       "                                                body       created  \\\n",
       "0  Congrats /r/anxiety we've all made it to Wedne...  1.634735e+09   \n",
       "1  With both the subreddit and Discord continuing...  1.634606e+09   \n",
       "2  I went to get my haircut and the person cuttin...  1.635005e+09   \n",
       "\n",
       "                                        reddit_punct  \\\n",
       "0  Congrats ranxiety weve all made it to Wednesda...   \n",
       "1  With both the subreddit and Discord continuing...   \n",
       "2  I went to get my haircut and the person cuttin...   \n",
       "\n",
       "                                    reddit_tokenized  \n",
       "0  [congrats, ranxiety, weve, all, made, it, to, ...  \n",
       "1  [with, both, the, subreddit, and, discord, con...  \n",
       "2  [i, went, to, get, my, haircut, and, the, pers...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "df['reddit_tokenized'] = df['reddit_punct'].apply(lambda x: tokenization(x.lower()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>reddit_punct</th>\n",
       "      <th>reddit_tokenized</th>\n",
       "      <th>reddit_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>Let your light shine!</td>\n",
       "      <td>17</td>\n",
       "      <td>qc0aqd</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qc0a...</td>\n",
       "      <td>23</td>\n",
       "      <td>Congrats /r/anxiety we've all made it to Wedne...</td>\n",
       "      <td>1.634735e+09</td>\n",
       "      <td>Congrats ranxiety weve all made it to Wednesda...</td>\n",
       "      <td>[congrats, ranxiety, weve, all, made, it, to, ...</td>\n",
       "      <td>[congrats, ranxiety, weve, made, wednesday, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>Looking for new mods! (subreddit and Discord)</td>\n",
       "      <td>12</td>\n",
       "      <td>qb0ort</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qb0o...</td>\n",
       "      <td>0</td>\n",
       "      <td>With both the subreddit and Discord continuing...</td>\n",
       "      <td>1.634606e+09</td>\n",
       "      <td>With both the subreddit and Discord continuing...</td>\n",
       "      <td>[with, both, the, subreddit, and, discord, con...</td>\n",
       "      <td>[subreddit, discord, continuing, grow, looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>fuck</td>\n",
       "      <td>159</td>\n",
       "      <td>qe7rl0</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/qe7r...</td>\n",
       "      <td>32</td>\n",
       "      <td>I went to get my haircut and the person cuttin...</td>\n",
       "      <td>1.635005e+09</td>\n",
       "      <td>I went to get my haircut and the person cuttin...</td>\n",
       "      <td>[i, went, to, get, my, haircut, and, the, pers...</td>\n",
       "      <td>[went, get, haircut, person, cutting, cut, way...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                          title  score      id  \\\n",
       "0  anxiety                          Let your light shine!     17  qc0aqd   \n",
       "1  anxiety  Looking for new mods! (subreddit and Discord)     12  qb0ort   \n",
       "2  anxiety                                           fuck    159  qe7rl0   \n",
       "\n",
       "  subreddit                                                url  num_comments  \\\n",
       "0   Anxiety  https://www.reddit.com/r/Anxiety/comments/qc0a...            23   \n",
       "1   Anxiety  https://www.reddit.com/r/Anxiety/comments/qb0o...             0   \n",
       "2   Anxiety  https://www.reddit.com/r/Anxiety/comments/qe7r...            32   \n",
       "\n",
       "                                                body       created  \\\n",
       "0  Congrats /r/anxiety we've all made it to Wedne...  1.634735e+09   \n",
       "1  With both the subreddit and Discord continuing...  1.634606e+09   \n",
       "2  I went to get my haircut and the person cuttin...  1.635005e+09   \n",
       "\n",
       "                                        reddit_punct  \\\n",
       "0  Congrats ranxiety weve all made it to Wednesda...   \n",
       "1  With both the subreddit and Discord continuing...   \n",
       "2  I went to get my haircut and the person cuttin...   \n",
       "\n",
       "                                    reddit_tokenized  \\\n",
       "0  [congrats, ranxiety, weve, all, made, it, to, ...   \n",
       "1  [with, both, the, subreddit, and, discord, con...   \n",
       "2  [i, went, to, get, my, haircut, and, the, pers...   \n",
       "\n",
       "                                      reddit_nonstop  \n",
       "0  [congrats, ranxiety, weve, made, wednesday, we...  \n",
       "1  [subreddit, discord, continuing, grow, looking...  \n",
       "2  [went, get, haircut, person, cutting, cut, way...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "    \n",
    "df['reddit_nonstop'] = df['reddit_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(data):\n",
    "    #Create a function to get the subjectivity\n",
    "     def getSubjectivity(text):\n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "  \n",
    "    #Create a function to get the polarity\n",
    "    def getPolarity(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    #Create two new columns ‘Subjectivity’ & ‘Polarity’\n",
    "    data[‘TextBlob_Subjectivity’] = data['body'].apply(getSubjectivity)\n",
    "    data[‘TextBlob_Polarity’] = data['body'].apply(getPolarity)\n",
    "    def getAnalysis(score):\n",
    "        if score < 0:\n",
    "            return ‘Negative’\n",
    "        elif score == 0:\n",
    "            return ‘Neutral’\n",
    "        else:\n",
    "            return ‘Positive’\n",
    "    data['TextBlob_Analysis'] = data['TextBlob_Polarity'].apply(getAnalysis)\n",
    "return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524\n",
    "- https://towardsdatascience.com/cleaning-preprocessing-text-data-for-sentiment-analysis-382a41f150d6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
